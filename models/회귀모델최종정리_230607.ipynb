{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glvuJfTGtpxT",
        "outputId": "0d8a7abc-ac32-421a-f072-844a2bac5fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.802e+04, tolerance: 1.968e+01\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Model  Train RMSE  Train R^2  Test RMSE  Test R^2\n",
            "0  Linear Regression   10.058940   0.614318  10.996622  0.506231\n",
            "1   Ridge Regression   10.032291   0.616359  10.796114  0.524073\n",
            "2   Lasso Regression   10.415383   0.586501  10.349157  0.562664\n",
            "3         ElasticNet   10.068659   0.613573  10.853918  0.518963\n",
            "4      Random Forest    4.262460   0.930746   9.412568  0.638239\n",
            "5  Gradient Boosting    1.108863   0.995313   9.372124  0.641341\n",
            "6            XGBoost    1.006409   0.996139   9.326375  0.644834\n",
            "7           LightGBM    1.946590   0.985556  10.446396  0.554407\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "import xgboost\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# import feature_pp as fp\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/1조(semi)_데이터분석엔지니어24회차/데이터/regression_df.csv\")\n",
        "df= df[:1000]\n",
        "\n",
        "# get dataframe\n",
        "def get_xy(df):\n",
        "    X = df.drop([\"rent_adjusted\"], axis=1)\n",
        "    y = df[\"rent_adjusted\"]\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# 데이터 분할\n",
        "def data_split(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, stratify=df[\"service_type\"], random_state=42\n",
        "    )\n",
        "    X_train = pd.get_dummies(X_train)\n",
        "    X_test = pd.get_dummies(X_test)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "# poly_transform\n",
        "def poly_data(X_train, X_test):\n",
        "    # 2차 다항식으로 변환\n",
        "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "    X_poly_2_train = poly.fit_transform(X_train)\n",
        "    X_poly_2_test = poly.fit_transform(X_test)\n",
        "    return X_poly_2_train, X_poly_2_test\n",
        "\n",
        "\n",
        "# ML 모델 with best parameter\n",
        "def get_model():\n",
        "    lr = LinearRegression()\n",
        "    lr_ridge = Ridge(alpha=0.001)\n",
        "    lr_lasso = Lasso(alpha=0.1)\n",
        "    elastic = ElasticNet(alpha=0.0000155, l1_ratio=0.005, max_iter=500)\n",
        "    rf = RandomForestRegressor(\n",
        "        n_estimators=621, min_samples_leaf=1, min_samples_split=5\n",
        "    )\n",
        "    gb = GradientBoostingRegressor(n_estimators=954, learning_rate=0.09, subsample=0.8)\n",
        "    xgb = xgboost.XGBRegressor(\n",
        "        n_jobs=-1,\n",
        "        n_estimators=2000,\n",
        "        colsample_bytree=0.75,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=6,\n",
        "        subsample=0.75,\n",
        "        gamma=10,\n",
        "    )\n",
        "    lgbm = LGBMRegressor(\n",
        "        n_estimators=448,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=15,\n",
        "        min_child_samples=40,\n",
        "        num_leaves=23,\n",
        "    )\n",
        "    return lr, lr_ridge, lr_lasso, elastic, rf, gb, xgb, lgbm\n",
        "\n",
        "\n",
        "# fit\n",
        "def model_eval(model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "    r2_train = r2_score(y_train, y_pred_train)\n",
        "\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "    r2_test = r2_score(y_test, y_pred_test)\n",
        "\n",
        "    train_rmse = np.sqrt(abs(mse_train))\n",
        "    test_rmse = np.sqrt(abs(mse_test))\n",
        "\n",
        "    return train_rmse, r2_train, test_rmse, r2_test\n",
        "\n",
        "\n",
        "# 스케일링 적용 함수\n",
        "def apply_scaling(scaling_method, X_train, X_test):\n",
        "    if scaling_method == \"standard\":\n",
        "        scaler = StandardScaler()\n",
        "    elif scaling_method == \"minmax\":\n",
        "        scaler = MinMaxScaler()\n",
        "    elif scaling_method == \"robust\":\n",
        "        scaler = RobustScaler()\n",
        "    elif scaling_method == \"poly\":\n",
        "        X_train_scaled, X_test_scaled = poly_data(X_train, X_test)\n",
        "        return X_train_scaled, X_test_scaled\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported scaling method\")\n",
        "\n",
        "    # 훈련 데이터에 스케일링 적용\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "    # 테스트 데이터에 스케일링 적용\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    return X_train_scaled, X_test_scaled\n",
        "\n",
        "\n",
        "def get_model_result_df(scaling_method):\n",
        "    X, y = get_xy(df)\n",
        "\n",
        "    # 데이터 분할\n",
        "    X_train, X_test, y_train, y_test = data_split(X, y)\n",
        "\n",
        "    # 스케일링 적용\n",
        "    scaling_method = scaling_method  # 원하는 스케일링 방법 선택\n",
        "    X_train_scaled, X_test_scaled = apply_scaling(scaling_method, X_train, X_test)\n",
        "\n",
        "    # 사용할 모델 가져오기\n",
        "    lr, lr_ridge, lr_lasso, elastic, rf, gb, xgb, lgbm = get_model()\n",
        "\n",
        "    # 모델 평가\n",
        "    models = [lr, lr_ridge, lr_lasso, elastic, rf, gb, xgb, lgbm]\n",
        "    model_names = [\n",
        "        \"Linear Regression\",\n",
        "        \"Ridge Regression\",\n",
        "        \"Lasso Regression\",\n",
        "        \"ElasticNet\",\n",
        "        \"Random Forest\",\n",
        "        \"Gradient Boosting\",\n",
        "        \"XGBoost\",\n",
        "        \"LightGBM\",\n",
        "    ]\n",
        "    results = []\n",
        "\n",
        "    for model, name in zip(models, model_names):\n",
        "        train_rmse, r2_train, test_rmse, r2_test = model_eval(\n",
        "            model, X_train_scaled, X_test_scaled, y_train, y_test\n",
        "        )\n",
        "        results.append((name, train_rmse, r2_train, test_rmse, r2_test))\n",
        "\n",
        "    # 결과 출력\n",
        "    results_df = pd.DataFrame(\n",
        "        results, columns=[\"Model\", \"Train RMSE\", \"Train R^2\", \"Test RMSE\", \"Test R^2\"]\n",
        "    )\n",
        "    print(results_df)\n",
        "\n",
        "\n",
        "get_model_result_df(\"standard\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u6gRQpEbuHfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 파라미터 서치"
      ],
      "metadata": {
        "id": "u62EXUo44V8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nrEcozrG4Yzq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}